# weeks 1-2: spark, then why (3 lectures; 2 recitations; entity-resolution HW)
#  cost of ops, streaming, hadoop
#  hadoop/spark model of computation (w/o caching)
#  spark key ideas
#    abstractions on top of map-reduce
#    - RDDs
#    - computation graph via lazy transformations and eager 'actions'
#    caching 
#  workflows for joins and etc
#    shorter-stream-and-sort, parallel-stream-and-sort are better paced
#    possible: phrase-finding-* simjoins-complete.pptx simjoins-intro naive-bayes
#    note also simjoins-2 - has A* search
#  fast inner product search / hybrid search
#  haitian - practical aspects of training LLMs at scale - maybe a 40min talk in mid-March
#  recitations: pyspark, linear algebra

- title: 'Overview'
  summary: 'Course Overview, History, Review of Complexity'
  slide_link: https://drive.google.com/file/d/1bOg-_CoG7hWjoZ0vlRQx_4dUaJUOB-OJ/view?usp=sharing
  movie_link: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=7402cfaa-439c-4938-8a61-b26401406afd
  content:
  - 605-administrivia.pptx
  - bigdata-history.pptx
  - chinchilla-scaling.pptx
  - complexity.pptx #also cost of operations
  - short-stream-and-sort.pptx
- title: 'Map-Reduce and Spark'
  summary: 'Stream and sort paradigm, map-reduce'
  slide_link: https://drive.google.com/file/d/1qgMx4UeB13HSoRBEsuDfItJ1PjU2lozz/view?usp=drive_link
  hw_link: https://github.com/10605/S25_HW1/archive/refs/tags/hw1.tar.gz
  movie_link: https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b41db72c-4aa9-4f61-bf0a-b266013d2bc9
  content: #ER and HW1 task
  - cost-of-operations.pptx
  - density-vs-naive-bayes.pptx
  - short-stream-sort-to-mr.pptx # keys and values
  - map-reduce-frameworks.pptx
  - map-reduce-abstractions.pptx #can simplify - (w, {y: n(w,y)}) join (w, docid) 
  - spark-overview.pptx
  - '* HW - Entity Resolution and Naive Bayes in Spark'
- title: 'Recitation: PySpark'
  summary: ''
  type: recitation
- title: 'Workflows for Map-Reduce Systems'
  summary: Motivating Spark/Hadoop; PageRank, K-Means, and Iterative Map-Reduce
  slide_link: https://drive.google.com/file/d/1AsxiIdiYa8U11G7nr5_jctoRjddVsc8a/view?usp=drive_link
  content: #add motivation for entity resolution
  - recap-longer-stream-sort-mr.pptx
  - parallel-stream-and-sort.pptx
  - spark-details.pptx
  - comparing-corpora.pptx
  - pagerank-intro.pptx
  - iterative-pagerank-in-spark.pptx
  - k-means-in-spark-example.pptx
  - matmul-in-spark.pptx
- title: 'Recitation: Linear Algebra Review'
  summary: ''
  type: recitation

# weeks 3-4: optimization (4 lectures; 2 recitations; distrib linreg HW)
#  learning as optimization: linear reg, pca, and logreg
#  parallel optimization: param mixing, all-reduce
#  parallel optimization: matrix factorization
#  parallel optimization abstractions: autodiff 
#  recitations: AWS, probabilities
- title: Learning as Optimization
  summary: Linear Regression, Logistic Regression
- title: Parallel Optimization 1
  summary: Parameter Mixing, All-Reduce
  content: 
  - '* HW parallel linear regression with Spark'
- title: 'No Recitation'
  type: recitation
  summary: ''

- title: Parallel Optimization 2
  summary: Matrix Factorization and Other Tasks
- title: 'AutoDiff as Optimization Infrastructure'
  summary: ''
- title: 'Recitation: Probability for LSH '
  type: recitation
  summary: ''

# weeks 5-6: randomized algorithms and etc (4 lectures; 2 recitations; LSH HW)
#  bloom filters, cm sketch, lsh, online lsh
#  distributed graph algorithms
- title: Randomized Algorithms 1
  summary: Locality-Sensitive Hashing
  content:
  - '* HW: LSH'
- title: Randomized Algorithms 2
  summary: Bloom Filters and Count-Min-Sketchs
- title: 'Recitation: AWS'
  type: recitation

- title: 'Parallel Optimization with GPUs 1'
  summary: ''
  content:
  - gpu-intro.pptx
  - gpu-programming-intro.pptx
  - vectorize-logreg.pptx
- title: 'Parallel Optimization with GPUs 2'
  summary: ''
  content: []
- title: 'Recitation: Practice Exam'
  type: recitation
  summary: ''
  content:
  - '* Previous HW due'

# week 7: review and midterm
- title: Exam Review and QA
- title: Exam 1

# week 8: spring break
# week 9-10: deep learning architectures (LoRA HW)
#  lstms, transformers and matmul
#  adapters, LoRA and related methods
#  more on autodiff and distributed computation
#  more on distributed optimization
- title: 'Deep Learning: Background and Architectures'
  summary: 'History, expressiveness, instability'
  content:
  - '* HW: LoRA'
- title: 'Deep Learning: Architectures and Param Efficient Tuning'
  summary: 'Transformers, Adapters and LoRA'
- title: 'Recitation: PyTorch'
  type: recitation

- title: 'Deep Learning: Scaling Transformers 1'
  summary: 'Key-value caches and memory'
  content: []
- title: 'Deep Learning: Scaling Transformers 1'
  summary: 'Large-context transformers'
  content: []
- title: Recitation TBD
  summary: 
  content: []

# weeks 12-13: scaling deep learning: long context models, KV caching; BTM  (GPT-2 HW + miniproject)

- title: Hyperparameter Search and Scaling Laws
  summary: 
  content: []
  content:
  - '* HW: GPT-2 Training and Miniproject released'
- title: Distributed Training Methods
  summary: Branch-Train-Merge
- title: Recitation TBD
  type: recitation
#
- title: Contrastive learning 1
  summary: training for retrieval and similarities
  content: []
- title: Retrieval Augmented Generation 1
# carnival

- title: Retrieval Augmented Generation 2
  content:
  - '* Previous HW due'
- title: Parameter Servers
  content: []
- title: Recitation TBD
  type: recitation

# weeks 14-15: other topics

- title: Scalable Graph Processing 1
- title: Scalable Graph Processing 2
- title: Recitation TBD
  type: recitation

# week 16: review and final
- title: Exam Review and QA
  content:
  - '* Miniproject due'
- title: Exam 2
##############################################################################
# Weeks 1-2 - spark/hadoop/streaming, soft joins - 3 lectures
##############################################################################
